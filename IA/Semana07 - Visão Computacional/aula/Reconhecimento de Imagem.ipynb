{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1> Visão Computacional </H1>\n",
    "\n",
    "<a href='https://sites.google.com/serpro.gov.br/didescientistadados2019/hands-on/vis%C3%A3o-computacional?authuser=0' target='_blank'> Hands-on Visão Computacional </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visão Computacional -> trata-se de conferir a máquinas e computadores a capacidade de “enxergar”, utilizando para isso uma série de ferramentas tecnológicas avançadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.learnopencv.com/install-opencv-3-and-dlib-on-windows-python-only/\n",
    "# https://stackoverflow.com/questions/37085665/in-which-conda-environment-is-jupyter-executing\n",
    "# https://janakiev.com/blog/jupyter-virtual-envs/\n",
    "\n",
    "# mkdir VC\n",
    "# cd VC\n",
    "\n",
    "# Para instalação\n",
    "# conda create --name VC-env python=3.7\n",
    "# conda activate vc-env\n",
    "\n",
    "# arquivo requirements.txt \n",
    "# \n",
    "# jupyter\n",
    "# matplotlib\n",
    "# numpy \n",
    "# scikit-learn\n",
    "# opencv-contrib-python \n",
    "# opencv-python\n",
    "# opencv-utils\n",
    "# scipy\n",
    "\n",
    "# pip install -r requirements.txt\n",
    "\n",
    "# Para subir o ambiente produtivo\n",
    "# conda activate vc-env\n",
    "# jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste de imagem - Encontrou imagem em \n",
    "# https://www.digitalocean.com/community/tutorials/how-to-detect-and-extract-faces-from-an-image-with-opencv-and-python\n",
    "\n",
    "import cv2\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definição da imagem para testar, deve vir de algum sistema externo\n",
    "imagePath= 'CNH_01.jpg'\n",
    "image = cv2.imread(imagePath)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# https://github.com/opencv/opencv/blob/master/data/haarcascades/haarcascade_frontalface_default.xml\n",
    "faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "faces = faceCascade.detectMultiScale(\n",
    "    gray,\n",
    "    scaleFactor=1.3,\n",
    "    minNeighbors=5,\n",
    "    minSize=(10, 10)\n",
    ")\n",
    "\n",
    "print(\"Encontrou {0} faces\".format(len(faces)))\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    roi_color = image[y:y + h, x:x + w]\n",
    "    print(\"Objeto encontrado. Salvando...\")\n",
    "    cv2.imwrite(str(w) + str(h) + '_faces.jpg', roi_color)\n",
    "status = cv2.imwrite('faces_detected.jpg', image)\n",
    "print(\"Imagem faces_detectada.jpg written to filesystem: \", status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
